{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('D:/学习/集思项目/final project/train.csv')\n",
    "X = pd.read_csv(r'D:/学习/集思项目/final project/tfidf2.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>34634</th>\n",
       "      <th>34635</th>\n",
       "      <th>34636</th>\n",
       "      <th>34637</th>\n",
       "      <th>34638</th>\n",
       "      <th>34639</th>\n",
       "      <th>34640</th>\n",
       "      <th>34641</th>\n",
       "      <th>34642</th>\n",
       "      <th>34643</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.482953</td>\n",
       "      <td>30.570149</td>\n",
       "      <td>18.022587</td>\n",
       "      <td>6.971426</td>\n",
       "      <td>5.800844</td>\n",
       "      <td>8.37292</td>\n",
       "      <td>4.12232</td>\n",
       "      <td>2.206366</td>\n",
       "      <td>12.935958</td>\n",
       "      <td>2.680922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.206366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34644 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0          1          2         3         4        5        6      \\\n",
       "0  4.482953  30.570149  18.022587  6.971426  5.800844  8.37292  4.12232   \n",
       "1  0.000000   0.000000   0.000000  0.000000  0.000000  0.00000  0.00000   \n",
       "2  0.000000   0.000000   0.000000  0.000000  0.000000  0.00000  0.00000   \n",
       "3  0.000000   0.000000   0.000000  0.000000  0.000000  0.00000  0.00000   \n",
       "4  0.000000   0.000000   0.000000  0.000000  0.000000  0.00000  0.00000   \n",
       "\n",
       "      7          8         9      ...  34634  34635  34636  34637  34638  \\\n",
       "0  2.206366  12.935958  2.680922  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "1  0.000000   0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2  2.206366   0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "3  0.000000   0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "4  0.000000   0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   34639  34640  34641  34642  34643  \n",
       "0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 34644 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = data[['Computer Science','Physics','Mathematics','Statistics','Quantitative Biology','Quantitative Finance']]\n",
    "Y = Y.head(10000)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sum = np.row_stack((X_train, X_test))\n",
    "Y_sum = np.row_stack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "\n",
    "X_sparse = sparse.csr_matrix(X_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x34644 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 686140 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(X_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 8.59709375e-03, 8.03943867e-03, ...,\n",
       "        2.83923161e-03, 4.74126284e-03, 5.39335239e-02],\n",
       "       [8.59709375e-03, 1.00000000e+00, 1.82865448e-03, ...,\n",
       "        2.01976232e-03, 3.98288973e-03, 3.42897602e-03],\n",
       "       [8.03943867e-03, 1.82865448e-03, 1.00000000e+00, ...,\n",
       "        3.18815544e-03, 1.06452928e-02, 3.92124789e-03],\n",
       "       ...,\n",
       "       [2.83923161e-03, 2.01976232e-03, 3.18815544e-03, ...,\n",
       "        1.00000000e+00, 8.43437042e-03, 9.41189954e-04],\n",
       "       [4.74126284e-03, 3.98288973e-03, 1.06452928e-02, ...,\n",
       "        8.43437042e-03, 1.00000000e+00, 1.18537058e-02],\n",
       "       [5.39335239e-02, 3.42897602e-03, 3.92124789e-03, ...,\n",
       "        9.41189954e-04, 1.18537058e-02, 1.00000000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ML_KNN(k, X, Y, similarities):\n",
    "    \n",
    "    s = 1\n",
    "    m = len(X)\n",
    "    P1 = np.zeros((6,))\n",
    "    Pe1 = np.zeros((6, k + 1))\n",
    "    P0 = np.zeros((6,))\n",
    "    Pe0 = np.zeros((6, k + 1))\n",
    "    ind = np.argsort(-similarities)\n",
    "    \n",
    "    for i in range(6):\n",
    "        y = 0\n",
    "        for j in range(m):\n",
    "            if Y[j][i] == 1:\n",
    "                y = y + 1\n",
    "        P1[i] = (s + y) / (s * 2 + m)\n",
    "        P0[i] = 1 - P1[i]\n",
    "    \n",
    "    for i in range(6):\n",
    "        c1 = np.zeros(k + 1)\n",
    "        c0 = np.zeros(k + 1)\n",
    "        for j in range(m):\n",
    "            temp = 0\n",
    "            for kk in range(1,k + 1):\n",
    "                if Y[ind[j][kk]][i] == 1:\n",
    "                    temp = temp + 1\n",
    "            if Y[j][i] == 1:\n",
    "                c1[temp] = c1[temp] + 1\n",
    "            else:\n",
    "                c0[temp] = c0[temp] + 1\n",
    "        \n",
    "        for l in range(k + 1):\n",
    "            Pe1[i][l] = (s + c1[l]) / (s * (k + 1) + c1.sum())\n",
    "            Pe0[i][l] = (s + c0[l]) / (s * (k + 1) + c0.sum())\n",
    "            \n",
    "    return P1, P0, Pe1, Pe0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ML_KNN(k, P1, P0, Pe1, Pe0, test_Data, Y, similarities):\n",
    "    \n",
    "    rtl = np.zeros((test_Data.shape[0], 6))\n",
    "    m = test_Data.shape[0]\n",
    "    predict_labels = np.zeros((m, 6))\n",
    "    ind = np.argsort(-similarities)\n",
    "    \n",
    "    for i in range(m):\n",
    "        for j in range(6):\n",
    "            temp = 0\n",
    "            y1 = 0\n",
    "            y0 = 0\n",
    "            f = 1\n",
    "            count = 0\n",
    "            while count < k:\n",
    "                if ind[i + 8000][f] >= 8000:\n",
    "                    f = f + 1\n",
    "                    continue\n",
    "                else:\n",
    "                    count = count + 1\n",
    "                    if Y[ind[i + 8000][f]][j] == 1:\n",
    "                        temp = temp + 1\n",
    "                    f = f + 1\n",
    "            y1 = P1[j] * Pe1[j][temp]\n",
    "            y0 = P0[j] * Pe0[j][temp]\n",
    "            rtl[i][j] = P1[j] * Pe1[j][temp] / (P1[j] * Pe1[j][temp] + P0[j] * Pe0[j][temp])\n",
    "            if y1 > y0:\n",
    "                predict_labels[i][j] = 1\n",
    "            else:\n",
    "                predict_labels[i][j] = 0\n",
    "    \n",
    "    return predict_labels, rtl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hloss(predict_label, true_label):\n",
    "  #预测集行数等于验证集大小，预测集列数等于验证集label大小\n",
    "    data_num = predict_label.shape[0]\n",
    "    label_num = predict_label.shape[1]\n",
    "    hloss = 0\n",
    "    for i in range(data_num):\n",
    "        bias = 0\n",
    "        for j in range(label_num):\n",
    "            if predict_label[i,j] != true_label[i,j]:\n",
    "                bias += 1\n",
    "        hloss += bias/label_num\n",
    "    hloss = hloss/data_num\n",
    "    return hloss\n",
    "\n",
    "\n",
    "\n",
    "def one_error(predict_rt, true_label): \n",
    "    \n",
    "    data_num = predict_rt.shape[0]\n",
    "    label_num = predict_rt.shape[1]\n",
    "    one_error_num = 0\n",
    "    for i in range(data_num):\n",
    "        rtl = list(predict_rt[i])\n",
    "        max_index = rtl.index(max(rtl))\n",
    "        if true_label[i,max_index] != 1:\n",
    "            one_error_num += 1\n",
    "    \n",
    "    return one_error_num/data_num\n",
    "\n",
    "def sort_both(list_rtl, list_target):\n",
    "    for j in range(len(list_rtl)-1):\n",
    "        for k in range(j,len(list_rtl)):\n",
    "            if list_rtl[j] <= list_rtl[k]:\n",
    "                temp1 =list_rtl[j]\n",
    "                temp2 =list_target[j]\n",
    "                list_rtl[j] = list_rtl[k]\n",
    "                list_target[j] = list_target[k]\n",
    "                list_rtl[k] = temp1 \n",
    "                list_target[k] = temp2\n",
    "    \n",
    "    return list_rtl,list_target\n",
    "\n",
    "def coverage(predict_rt, true_label):\n",
    "    data_num = predict_rt.shape[0]\n",
    "    label_num = predict_rt.shape[1]\n",
    "    coverage1 = 0\n",
    "    for i in range(data_num):\n",
    "        max_rank = 0\n",
    "        rtl = list(predict_rt[i])\n",
    "        target = list(true_label[i])\n",
    "        rtl, target = sort_both(rtl,target)\n",
    "\n",
    "        for j in range(len(rtl)):\n",
    "            if target[j] == 1:\n",
    "                max_rank = j+1\n",
    "        coverage1 += max_rank\n",
    "    \n",
    "    return (coverage1/data_num-1)\n",
    "\n",
    "\n",
    "def rloss(predict_rt, true_label):\n",
    "    #import pdb; pdb.set_trace()\n",
    "\n",
    "    data_num = predict_rt.shape[0]\n",
    "    label_num = predict_rt.shape[1]\n",
    "    r_loss = 0\n",
    "    for i in range(data_num):\n",
    "        index_1 = []\n",
    "        index_0 = []\n",
    "        rank_loss = 0\n",
    "        rtl = list(predict_rt[i])\n",
    "        target = list(true_label[i])\n",
    "        rtl, target = sort_both(rtl,target)\n",
    "        for j in range(label_num):\n",
    "            if target[j] == 1:\n",
    "                index_1.append(j)\n",
    "            else:\n",
    "                index_0.append(j)\n",
    "      \n",
    "        m = len(index_1)\n",
    "        n = len(index_0)\n",
    "        for j in range(m):\n",
    "            for k in range(n):\n",
    "                if index_0[k] <= index_1[j]:\n",
    "                    rank_loss += 1\n",
    "      \n",
    "        r_loss += rank_loss/(m*n)\n",
    "    return r_loss/data_num\n",
    "  \n",
    "\n",
    "def avgprec(predict_rt, true_label):\n",
    "\n",
    "    data_num = predict_rt.shape[0]\n",
    "    label_num = predict_rt.shape[1]\n",
    "    avg_prec = 0\n",
    "    for i in range(data_num):\n",
    "        index_1 = []\n",
    "        temp_prec = 0\n",
    "        rtl = list(predict_rt[i])\n",
    "        target = list(true_label[i])\n",
    "        rtl, target = sort_both(rtl,target)\n",
    "        for j in range(label_num):\n",
    "            if target[j] == 1:\n",
    "                index_1.append(j)\n",
    "        for k in range(len(index_1)):\n",
    "            temp_prec += (k+1)/(index_1[k]+1)\n",
    "      \n",
    "        avg_prec += temp_prec/len(index_1)\n",
    "    \n",
    "    return avg_prec/data_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  0\n",
      "Hamming Loss is 0.20583333333333587\n",
      "One Error is 0.6\n",
      "Coverage is 1.5394999999999999\n",
      "Ranking Loss is 0.24941805555555305\n",
      "Average Precision is 0.6103527777777791\n",
      "\n",
      "\n",
      "k =  1\n",
      "Hamming Loss is 0.28116666666666545\n",
      "One Error is 0.6775\n",
      "Coverage is 1.7320000000000002\n",
      "Ranking Loss is 0.2956000000000007\n",
      "Average Precision is 0.5646666666666689\n",
      "\n",
      "\n",
      "k =  2\n",
      "Hamming Loss is 0.2558333333333324\n",
      "One Error is 0.667\n",
      "Coverage is 1.7405\n",
      "Ranking Loss is 0.29728888888888905\n",
      "Average Precision is 0.5670861111111141\n",
      "\n",
      "\n",
      "k =  3\n",
      "Hamming Loss is 0.2764999999999991\n",
      "One Error is 0.6725\n",
      "Coverage is 1.7275\n",
      "Ranking Loss is 0.2937513888888883\n",
      "Average Precision is 0.5671513888888914\n",
      "\n",
      "\n",
      "k =  4\n",
      "Hamming Loss is 0.27049999999999885\n",
      "One Error is 0.6825\n",
      "Coverage is 1.7599999999999998\n",
      "Ranking Loss is 0.3019805555555559\n",
      "Average Precision is 0.5600472222222249\n",
      "\n",
      "\n",
      "k =  5\n",
      "Hamming Loss is 0.2772499999999992\n",
      "One Error is 0.688\n",
      "Coverage is 1.7715\n",
      "Ranking Loss is 0.3034486111111106\n",
      "Average Precision is 0.556400000000003\n",
      "\n",
      "\n",
      "k =  6\n",
      "Hamming Loss is 0.27483333333333215\n",
      "One Error is 0.694\n",
      "Coverage is 1.7835\n",
      "Ranking Loss is 0.3069749999999992\n",
      "Average Precision is 0.551420833333337\n",
      "\n",
      "\n",
      "k =  7\n",
      "Hamming Loss is 0.2773333333333321\n",
      "One Error is 0.696\n",
      "Coverage is 1.7905000000000002\n",
      "Ranking Loss is 0.3070958333333329\n",
      "Average Precision is 0.5511833333333368\n",
      "\n",
      "\n",
      "k =  8\n",
      "Hamming Loss is 0.273833333333332\n",
      "One Error is 0.692\n",
      "Coverage is 1.8115\n",
      "Ranking Loss is 0.310940277777777\n",
      "Average Precision is 0.5494125000000034\n",
      "\n",
      "\n",
      "k =  9\n",
      "Hamming Loss is 0.2779999999999985\n",
      "One Error is 0.692\n",
      "Coverage is 1.8165\n",
      "Ranking Loss is 0.3121374999999994\n",
      "Average Precision is 0.5503388888888924\n",
      "\n",
      "\n",
      "k =  10\n",
      "Hamming Loss is 0.27691666666666526\n",
      "One Error is 0.6935\n",
      "Coverage is 1.8304999999999998\n",
      "Ranking Loss is 0.3155527777777775\n",
      "Average Precision is 0.5483861111111147\n",
      "\n",
      "\n",
      "k =  11\n",
      "Hamming Loss is 0.27449999999999847\n",
      "One Error is 0.6915\n",
      "Coverage is 1.8355000000000001\n",
      "Ranking Loss is 0.316558333333333\n",
      "Average Precision is 0.5482861111111146\n",
      "\n",
      "\n",
      "k =  12\n",
      "Hamming Loss is 0.2776666666666655\n",
      "One Error is 0.6885\n",
      "Coverage is 1.8410000000000002\n",
      "Ranking Loss is 0.31774999999999987\n",
      "Average Precision is 0.5490263888888923\n",
      "\n",
      "\n",
      "k =  13\n",
      "Hamming Loss is 0.2771666666666656\n",
      "One Error is 0.689\n",
      "Coverage is 1.8435000000000001\n",
      "Ranking Loss is 0.3170208333333331\n",
      "Average Precision is 0.5488777777777811\n",
      "\n",
      "\n",
      "k =  14\n",
      "Hamming Loss is 0.2780833333333322\n",
      "One Error is 0.69\n",
      "Coverage is 1.8490000000000002\n",
      "Ranking Loss is 0.3190930555555556\n",
      "Average Precision is 0.5475930555555594\n",
      "\n",
      "\n",
      "k =  15\n",
      "Hamming Loss is 0.27658333333333196\n",
      "One Error is 0.691\n",
      "Coverage is 1.8479999999999999\n",
      "Ranking Loss is 0.31903055555555554\n",
      "Average Precision is 0.5473680555555592\n",
      "\n",
      "\n",
      "k =  16\n",
      "Hamming Loss is 0.2796666666666656\n",
      "One Error is 0.685\n",
      "Coverage is 1.8475000000000001\n",
      "Ranking Loss is 0.319248611111111\n",
      "Average Precision is 0.5492375000000034\n",
      "\n",
      "\n",
      "k =  17\n",
      "Hamming Loss is 0.2751666666666655\n",
      "One Error is 0.69\n",
      "Coverage is 1.8485\n",
      "Ranking Loss is 0.31986666666666663\n",
      "Average Precision is 0.5479527777777811\n",
      "\n",
      "\n",
      "k =  18\n",
      "Hamming Loss is 0.2798333333333321\n",
      "One Error is 0.6905\n",
      "Coverage is 1.831\n",
      "Ranking Loss is 0.3166472222222223\n",
      "Average Precision is 0.5496152777777809\n",
      "\n",
      "\n",
      "k =  19\n",
      "Hamming Loss is 0.278083333333332\n",
      "One Error is 0.6895\n",
      "Coverage is 1.8365\n",
      "Ranking Loss is 0.317698611111111\n",
      "Average Precision is 0.5495791666666698\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_sparse = sparse.csr_matrix(X_train)\n",
    "X_train_similarities = cosine_similarity(X_train_sparse)\n",
    "true_labels = Y[8000:][:]\n",
    "kk = 20\n",
    "Hamming_Loss = np.zeros(kk)\n",
    "One_Error = np.zeros(kk)\n",
    "Coverage = np.zeros(kk)\n",
    "Ranking_Loss = np.zeros(kk)\n",
    "Average_Precision = np.zeros(kk)\n",
    "\n",
    "for k in range(kk):\n",
    "    P1, P0, Pe1, Pe0 = fit_ML_KNN(k, X_train, y_train, X_train_similarities)\n",
    "    predict_labels, predict_rtl = predict_ML_KNN(k, P1, P0, Pe1, Pe0, X_test, Y_sum, similarities)\n",
    "    Hamming_Loss[k] = hloss(predict_labels, true_labels)\n",
    "    One_Error[k] = one_error(predict_rtl, true_labels)\n",
    "    Coverage[k] = coverage(predict_rtl, true_labels)\n",
    "    Ranking_Loss[k] = rloss(predict_rtl, true_labels)\n",
    "    Average_Precision[k] = avgprec(predict_rtl, true_labels)\n",
    "    print('k = ',k)\n",
    "    print('Hamming Loss is',Hamming_Loss[k])\n",
    "    print('One Error is',One_Error[k])\n",
    "    print('Coverage is',Coverage[k])\n",
    "    print('Ranking Loss is',Ranking_Loss[k])\n",
    "    print('Average Precision is',Average_Precision[k])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x146824d2d08>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.arange(kk)\n",
    "plt.plot(X, Hamming_Loss)\n",
    "plt.plot(X, One_Error)\n",
    "plt.plot(X, Coverage)\n",
    "plt.plot(X, Ranking_Loss)\n",
    "plt.plot(X, Average_Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20583333, 0.28116667, 0.25583333, 0.2765    , 0.2705    ,\n",
       "       0.27725   , 0.27483333, 0.27733333, 0.27383333, 0.278     ,\n",
       "       0.27691667, 0.2745    , 0.27766667, 0.27716667, 0.27808333,\n",
       "       0.27658333, 0.27966667, 0.27516667, 0.27983333, 0.27808333])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hamming_Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6   , 0.6775, 0.667 , 0.6725, 0.6825, 0.688 , 0.694 , 0.696 ,\n",
       "       0.692 , 0.692 , 0.6935, 0.6915, 0.6885, 0.689 , 0.69  , 0.691 ,\n",
       "       0.685 , 0.69  , 0.6905, 0.6895])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One_Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5395, 1.732 , 1.7405, 1.7275, 1.76  , 1.7715, 1.7835, 1.7905,\n",
       "       1.8115, 1.8165, 1.8305, 1.8355, 1.841 , 1.8435, 1.849 , 1.848 ,\n",
       "       1.8475, 1.8485, 1.831 , 1.8365])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24941806, 0.2956    , 0.29728889, 0.29375139, 0.30198056,\n",
       "       0.30344861, 0.306975  , 0.30709583, 0.31094028, 0.3121375 ,\n",
       "       0.31555278, 0.31655833, 0.31775   , 0.31702083, 0.31909306,\n",
       "       0.31903056, 0.31924861, 0.31986667, 0.31664722, 0.31769861])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ranking_Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61035278, 0.56466667, 0.56708611, 0.56715139, 0.56004722,\n",
       "       0.5564    , 0.55142083, 0.55118333, 0.5494125 , 0.55033889,\n",
       "       0.54838611, 0.54828611, 0.54902639, 0.54887778, 0.54759306,\n",
       "       0.54736806, 0.5492375 , 0.54795278, 0.54961528, 0.54957917])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Average_Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "date_palatte = [(0.20651240887022015, 0.3755393698154809, 0.5856904756194529),\n",
    " (0.3720866446574984, 0.6378633419526029, 0.5550368905837924),\n",
    " (0.15908978777909805, 0.2627191708800849, 0.2704304083743111),\n",
    " (0.18673086084284554, 0.40157226483269637, 0.4175589767109701)]\n",
    "\n",
    "data = pd.DataFrame(columns = ['Hamming Loss','One Error','Coverage','Ranking Loss','Average Precision'])\n",
    "data['Hamming Loss'] = Hamming_Loss\n",
    "data['One Error'] = One_Error\n",
    "data['Coverage'] = Coverage\n",
    "data['Ranking Loss'] = Ranking_Loss\n",
    "data['Average Precision'] = Average_Precision\n",
    "data.to_excel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
